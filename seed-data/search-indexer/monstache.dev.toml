# connection settings

# connect to MongoDB using the following URL
#mongo-url =  "mongodb://localhost:27017/?directConnection=true"
mongo-url =  "mongodb://mongodb01:27017/?directConnection=true"
# connect to the Elasticsearch REST API at the following node URLs
#elasticsearch-urls = ["http://localhost:9200"] # to use local instance
elasticsearch-urls = ["http://es01:9200"] # to use local instance

# frequently required settings

# if you need to seed an index from a collection and not just listen and sync changes events
# you can copy entire collections or views from MongoDB to Elasticsearch
direct-read-namespaces = ["rampvis.onto_data", "rampvis.onto_vis", "rampvis.onto_page"]

# if you want to use MongoDB change streams instead of legacy oplog tailing use change-stream-namespaces
# change streams require at least MongoDB API 3.6+
# if you have MongoDB 4+ you can listen for changes to an entire database or entire deployment
# in this case you usually don't need regexes in your config to filter collections unless you target the deployment.
# to listen to an entire db use only the database name.  For a deployment use an empty string.
change-stream-namespaces = ["rampvis.onto_data", "rampvis.onto_vis", "rampvis.onto_page"]

# additional settings

# if you don't want to listen for changes to all collections in MongoDB but only a few
# e.g. only listen for inserts, updates, deletes, and drops from mydb.mycollection
# this setting does not initiate a copy, it is only a filter on the change event listener
## namespace-regex = '^mydb\.mycollection$'

# compress requests to Elasticsearch
gzip = true
# generate indexing statistics
stats = true
# index statistics into Elasticsearch
index-stats = true

# use the following PEM file for connections to MongoDB
## mongo-pem-file = "/path/to/mongoCert.pem"

# disable PEM validation
## mongo-validate-pem-file = false

# use the following user name for Elasticsearch basic auth
## elasticsearch-user = "someuser"

# use the following password for Elasticsearch basic auth
## elasticsearch-password = "somepassword"

# use 4 go routines concurrently pushing documents to Elasticsearch
elasticsearch-max-conns = 4

# use the following PEM file to connections to Elasticsearch
## elasticsearch-pem-file = "/path/to/elasticCert.pem"

# validate connections to Elasticsearch
## elastic-validate-pem-file = true

# propogate dropped collections in MongoDB as index deletes in Elasticsearch
dropped-collections = true
# propogate dropped databases in MongoDB as index deletes in Elasticsearch
dropped-databases = true
# do not start processing at the beginning of the MongoDB oplog
# if you set the replay to true you may see version conflict messages
# in the log if you had synced previously. This just means that you are replaying old docs which are already
# in Elasticsearch with a newer version. Elasticsearch is preventing the old docs from overwriting new ones.
replay = false
# resume processing from a timestamp saved in a previous run
resume = true
# do not validate that progress timestamps have been saved
resume-write-unsafe = false
# override the name under which resume state is saved
resume-name = "default"
# use a custom resume strategy (tokens) instead of the default strategy (timestamps)
# tokens work with MongoDB API 3.6+ while timestamps work only with MongoDB API 4.0+
resume-strategy = 1
# exclude documents whose namespace matches the following pattern
namespace-exclude-regex = '^mydb\.ignorecollection$'

# turn on indexing of GridFS file content
## index-files = true
# turn on search result highlighting of GridFS content
## file-highlighting = true
# index GridFS files inserted into the following collections
## file-namespaces = ["users.fs.files"]

# print detailed information including request traces
verbose = true
# enable clustering mode
cluster-name = 'apollo'
# do not exit after full-sync, rather continue tailing the oplog
exit-after-direct-reads = false

[[script]]
namespace = "rampvis.onto_page"
script = """
module.exports = function(doc) {

    // if (!doc || doc.pageType != "release") {
    if (!doc) {
        return;
    }

   if (doc.visId) {
       // Find vis function details
       ontoVis = findId(doc.visId, {
            database: "rampvis",
            collection: "onto_vis"
       });

       doc.visDescription = ontoVis.description;
       doc.visType = ontoVis.type;
       doc.visFunction = ontoVis.function;
   }

   if (doc.dataIds) {
        // Find data stream details
        ontoData = find({ _id : { $in : doc.dataIds } }, {
            database: "rampvis",
            collection: "onto_data",
            select: {
                _id: 0,
                description: 1,
                keywords: 1,
            },
        });

        if (ontoData && ontoData.length > 0) {
            keywords = [];
            description = [];

            // Concatinate descriptions and keywords
            ontoData.forEach(function(d) {
              description = description.concat(d.description)
              keywords = keywords.concat(d.keywords.split(', '))
            });

            // Remove duplicate descriptions
            descriptionUnique = description.filter(function(item, pos) {
              return description.indexOf(item) == pos;
            });

            // Remove duplicate keywords
            keywordsUnique = keywords.filter(function(item, pos) {
              return keywords.indexOf(item) == pos;
            });

            doc.dataDescription = descriptionUnique.join(' ');
            doc.keywords = keywordsUnique.join(' ');
        }
    }

   return doc;
}
"""
