{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ideal-commodity",
   "metadata": {},
   "source": [
    "# Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suspected-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import re\n",
    "import requests\n",
    "import h5py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.pardir)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "approved-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.naming import component_to_csv_file, format_component_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naughty-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../manifest/manifest.json') as f:\n",
    "    manifest = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "following-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stream(p, c, col=None):\n",
    "    stream = {\n",
    "        'urlCode': 'API_PY',\n",
    "        'endpoint': f'/stat/v1/data?product={p[\"product\"]}&component={c[\"name\"]}',\n",
    "        'dataType': c['dataType'],\n",
    "        'keywords': c['keywords'],\n",
    "        'description': ''\n",
    "    }\n",
    "    if col:\n",
    "        stream['endpoint'] += f'&field={col}'\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "departmental-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_streams(manifest, folder='../../data/live/'):\n",
    "    folder = Path(folder)\n",
    "    streams = []\n",
    "    for p in manifest:\n",
    "        for c in p['components']:\n",
    "            # Register the component\n",
    "            filepath = component_to_csv_file(folder, p['product'], c['name'])\n",
    "            df = pd.read_csv(filepath, index_col=0)\n",
    "            streams.append(create_stream(p, c))\n",
    "            \n",
    "            # Each field in a component csv file should be registered separately as individual data streams\n",
    "            if len(df.columns) > 1:\n",
    "                for col in df.columns:\n",
    "                    stream = create_stream(p, c, col)\n",
    "                    col = format_component_name(col)\n",
    "                    # female___1-14 years: 2 separate keywords\n",
    "                    extra_keywords = col.split('___') if '___' in col else [col]\n",
    "                    stream['keywords'] = stream['keywords'] + extra_keywords\n",
    "                    streams.append(stream)\n",
    "    return streams\n",
    "\n",
    "streams = generate_streams(manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "terminal-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_streams(streams, base_url='http://localhost:3000'):\n",
    "    # Can the endpoints be accessed?\n",
    "    for s in streams:\n",
    "        response = requests.get(base_url + s['endpoint'])\n",
    "        assert len(response.json())\n",
    "        \n",
    "    # There should be 15 age_group/gender/scotland stream, 1 overall and 14 age_group x gender for covid_deaths\n",
    "    subset = [s for s in streams if all(k in s['keywords'] for k in {'scotland', 'covid_deaths', 'age_group', 'gender'})]\n",
    "    assert len(subset) == 15\n",
    "    assert len([s for s in subset if 'male' in s['keywords']]) == 7\n",
    "    assert len([s for s in subset if 'female' in s['keywords']]) == 7\n",
    "    assert len([s for s in subset if '1_14_years' in s['keywords']]) == 2\n",
    "        \n",
    "test_streams(streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-louis",
   "metadata": {},
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "existing-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "    token = None\n",
    "    try:\n",
    "        res = requests.post('http://localhost:2000/api/v1/auth/login', {'password': \"zCEEwRSZGaSG2uL2\", 'email': \"phong@admin.com\"})\n",
    "        if res and res.json() and res.json()['token']:\n",
    "            token = res.json()['token']\n",
    "\n",
    "    except ConnectionError as e:\n",
    "        print(\"token request: error = \", e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong\", e)\n",
    "\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "token = get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "reported-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_register = {\"urlCode\":\"API_PY\",\"endpoint\":\"e3\",\"dataType\":\"timeseries\",\"description\":\"abc\",\"keywords\":[\"xl\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "widespread-mirror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjYwMzZkMDJkYzg2ZTkzZGZmY2Y0NWE5YSIsInJvbGUiOiJhZG1pbiIsInBlcm1pc3Npb25zIjp7InVzZXIiOnsicmVhZDpvd24iOlsiaWQiXSwidXBkYXRlOmFueSI6WyJwYXNzd29yZCIsInJvbGUiXSwicmVhZDphbnkiOlsiKiJdLCJjcmVhdGU6YW55IjpbIioiXSwiZGVsZXRlOmFueSI6WyIqIl19fSwiaWF0IjoxNjE0ODk0NjE5LCJleHAiOjI1NjE1Nzk0MTl9.M-B5vktEnevmgTOH5IDP8mZoYWV4Lw0Qh99KtQxIMPqk3y6Sctnn1C20e83_n5hTkLev7XxkUztDuSBB9wXJoAV8zImZWNO-x9y6Hf0cRx9nqG8BUklDdz2y5n4IVwfOsuAKToaXOs6Hy3h8mkjLA48Bu_BHIGeQj1-feESwOQE1jWT1C4ZxqCOmtanOQrth4iiYN5MsmO8ujlIoRDRB5REHfoNzndpE4xtD05-vyA3rdNhgRrtkT8cc2hYfaEkw1Z6MH9bDAPW8iIbhGqKOn2SwFQiU4i9W9JlERykeQv2sSrRdt7laXe8zUTorot35DOnwZllWjyf1F95aZHc67EHqdfeIEgTFbh8SEWR-XZj841UUVh29uGWtoXqk87TmfrKkC6l_qa7TgPzRRDMB6lwzWoZxsi7DvM4MbWEo_38ThpuxT-yQp1e-_h5e8jFPeR3Lgt_BSlZxt_i0cj1Ozv9xHEFQkRPu8XhT4h9DnxzVHVP6wcXGaQuEGrrKahplAwpmMqcCu-PZqTdWanOyBZqnLpoXc4Me6dnz_hJDbViFizfkIhkX6dr7SyCvTNTQ1kldPdA2zCuf0VP3FlJC7GDtRoLlY821kW8jCE91_zWck4sE5toyx6DEAZ5grPZteYaowSasllqyU_bMFnHq-3St5HswzxNZKac6cQKKD5Q'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "solved-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'keywords must be an array', 'status': 400, 'code': 'INVALID_QUERY_PARAMETERS'}\n"
     ]
    }
   ],
   "source": [
    "def register(data, token):\n",
    "    url = 'http://localhost:2000/api/v1/ontology/data'\n",
    "    headers = {'Authorization': 'Bearer ' + token}\n",
    "    try:\n",
    "        response = requests.post(url, data, headers=headers)\n",
    "        print(response.json())\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "register(data_to_register, token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramp-vis-api",
   "language": "python",
   "name": "ramp-vis-api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
